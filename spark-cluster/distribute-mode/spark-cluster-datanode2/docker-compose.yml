version: "2.2"
services:
  datanode2:
    image: tyrival/hadoop-datanode:2.7.4
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
      memlock:
        soft: -1
        hard: -1
    restart: always
    container_name: datanode2
    ports:
      - "50010:50010"
      - "50075:50075"
      - "50475:50475"
      - "50020:50020"
    volumes:
      - ./datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env

  worker1:
    image: gettyimages/spark:2.4.1-hadoop-3.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://2.82.6.45:7077
    container_name: worker1
    hostname: worker
    restart: always
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 4g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 8881
      - 9013
    ports:
      - 8081:8081
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data